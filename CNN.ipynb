{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "Clasificador segun perros y gatos\n",
    "\n",
    "     -Convolucion\n",
    "     -Pooling\n",
    "     -Convolucion\n",
    "     -Pooling\n",
    "     -Capas conectadas: conexiones neuronales (perceptrones)\n",
    "     -Output\n",
    "     \n",
    "Cada convolucion y pooling(hidden layer, interconectada), se obtiene un output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "#CALLBACKS\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#NAME= \"cats_vs_dogs_CNN-{}\".format(int(time.time())) #no se sobreescribe si se hacen arreglos\n",
    "\n",
    "#traigo el xtrain y el ytrain(labels)\n",
    "pickle_in= (open (\"modelo1/xtrain\", \"rb\"))\n",
    "xtrain=pickle.load(pickle_in)\n",
    "\n",
    "pickle_in= (open(\"modelo1/ytrain\", \"rb\"))\n",
    "ytrain=pickle.load(pickle_in)\n",
    "\n",
    "pickle_in= (open(\"modelo1/xtest\", \"rb\"))\n",
    "xtest=pickle.load(pickle_in)\n",
    "\n",
    "pickle_in= (open(\"modelo1/ytest\", \"rb\"))\n",
    "ytest=pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizar la data, escalar\n",
    "\n",
    "xtrain=xtrain/255\n",
    "xtest=xtest/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo_epochs-3-conv-256-neurons-1-dense-1562774778-\n",
      "Epoch 1/10\n",
      "1365/1365 [==============================] - 75s 55ms/sample - loss: 1.0531 - acc: 0.4601\n",
      "Epoch 2/10\n",
      "1365/1365 [==============================] - 78s 57ms/sample - loss: 0.5492 - acc: 0.7084\n",
      "Epoch 3/10\n",
      "1365/1365 [==============================] - 80s 59ms/sample - loss: 0.3810 - acc: 0.7993\n",
      "Epoch 4/10\n",
      "1365/1365 [==============================] - 76s 56ms/sample - loss: 0.2529 - acc: 0.8916\n",
      "Epoch 5/10\n",
      "1365/1365 [==============================] - 75s 55ms/sample - loss: 0.0883 - acc: 0.9685\n",
      "Epoch 6/10\n",
      "1365/1365 [==============================] - 78s 57ms/sample - loss: 0.0361 - acc: 0.9905\n",
      "Epoch 7/10\n",
      "1365/1365 [==============================] - 76s 56ms/sample - loss: 0.1328 - acc: 0.9546\n",
      "Epoch 8/10\n",
      "1365/1365 [==============================] - 75s 55ms/sample - loss: 0.0241 - acc: 0.9919\n",
      "Epoch 9/10\n",
      "1365/1365 [==============================] - 74s 54ms/sample - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1365/1365 [==============================] - 75s 55ms/sample - loss: 0.0020 - acc: 0.9993\n"
     ]
    }
   ],
   "source": [
    "dense_layers=[1] #coloco la cantidad a probar\n",
    "layer_sizes=[256]\n",
    "conv_layers=[3]\n",
    "\n",
    "\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME=\"modelo_epochs-{}-conv-{}-neurons-{}-dense-{}-\".format(conv_layer,layer_size,dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "            tensorboard= TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "            \n",
    "            #CREO EL MODELO\n",
    "            model= Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape=xtrain.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "\n",
    "                model.add(Conv2D(layer_size, (3,3)))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            model.add(Flatten()) #convierte lo 3D en 1D\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation(\"relu\"))\n",
    "\n",
    "            model.add(Dense(3))\n",
    "            model.add(Activation(\"softmax\"))\n",
    "            \n",
    "            model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                          optimizer=\"adam\", \n",
    "                          metrics=[\"accuracy\"])\n",
    "    \n",
    "            model.fit(xtrain,ytrain,\n",
    "                      batch_size=32, \n",
    "                      epochs=10, \n",
    "                      callbacks=[tensorboard]) #define que tantos datos pasara al mismo tiempo\n",
    "model.save(\"modelo1/ModeloFinal_3conv_1dense_256size.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x.shape[:1] (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 14s 24ms/sample - loss: 0.0050 - acc: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004961628528534729, 0.9982906]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"pesos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
